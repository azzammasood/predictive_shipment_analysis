{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ccd913d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Ahmad Uzzam\\personal\\Harsh\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import shap\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix, roc_curve, auc, roc_auc_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c967c718",
   "metadata": {},
   "source": [
    "### Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed9bc65d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/2206MCPC_VA (1).xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/data/2206MCPC_VA (1).xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Ahmad Uzzam\\personal\\Harsh\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32md:\\Ahmad Uzzam\\personal\\Harsh\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32md:\\Ahmad Uzzam\\personal\\Harsh\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32md:\\Ahmad Uzzam\\personal\\Harsh\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/2206MCPC_VA (1).xlsx'"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(r'data\\2206MCPC_VA (1).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20279b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05d4eb7",
   "metadata": {},
   "source": [
    "### Analyze the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c36e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display initial information about the dataset\n",
    "df_info = df.info()\n",
    "df_summary = df.describe(include='all')\n",
    "df_nulls = df.isna().sum()\n",
    "\n",
    "df_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cc03a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faf44ffe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_nulls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_nulls\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_nulls' is not defined"
     ]
    }
   ],
   "source": [
    "df_nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343e6e93",
   "metadata": {},
   "source": [
    "\n",
    "### Initial Overview of the Dataset\n",
    "\n",
    "- The dataset contains 10,418 rows and 34 columns.\n",
    "- The data includes a mix of numerical, categorical, and date-related features.\n",
    "- Several columns have missing values that will need to be addressed during preprocessing.\n",
    "- The dataset will undergo a detailed column-by-column analysis to identify any issues and prepare it for further modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4963e83a",
   "metadata": {},
   "source": [
    "\n",
    "### Column-by-Column Analysis\n",
    " \n",
    "\n",
    "#### **Age**\n",
    "- **Type**: Numerical (int)\n",
    "- **Analysis**: `Age` is a continuous variable representing the patient's age.\n",
    "\n",
    "#### **Age Group**\n",
    "- **Type**: Categorical (str)\n",
    "- **Analysis**: Represents predefined age groups.\n",
    "\n",
    "#### **Ethnicity**\n",
    "- **Type**: Categorical (str)\n",
    "- **Analysis**: Ethnicity of the patient.\n",
    "\n",
    "#### **Race**\n",
    "- **Type**: Categorical (str)\n",
    "- **Analysis**: Racial group of the patient.\n",
    "\n",
    "#### **Clinic assigned to**\n",
    "- **Type**: Categorical (str)\n",
    "- **Analysis**: The clinic where the patient is registered.\n",
    "\n",
    "#### **Zip Code**\n",
    "- **Type**: Categorical (str)\n",
    "- **Analysis**: Patient's zip code.\n",
    "\n",
    "#### **City**\n",
    "- **Type**: Categorical (str)\n",
    "- **Analysis**: Patient's city.\n",
    "\n",
    "#### **Year**\n",
    "- **Type**: Numerical (int)\n",
    "- **Analysis**: Year of the appointment or event.\n",
    "\n",
    "#### **Text Follow up Prior Scheduling Completed PrEP Appointment**\n",
    "- **Type**: Categorical (int, treated as binary)\n",
    "- **Analysis**: Indicates whether a text follow-up occurred before scheduling a completed PrEP appointment.\n",
    "\n",
    "#### **Call Follow up Prior Scheduling Completed PrEP Appointment**\n",
    "- **Type**: Categorical (int, treated as binary)\n",
    "- **Analysis**: Indicates whether a call follow-up occurred before scheduling a completed PrEP appointment.\n",
    "\n",
    "#### **Email Follow up Prior Scheduling Completed PrEP Appointment**\n",
    "- **Type**: Categorical (int, treated as binary)\n",
    "- **Analysis**: Indicates whether an email follow-up occurred before scheduling a completed PrEP appointment.\n",
    "\n",
    "#### **Other Follow up Prior Scheduling Completed PrEP Appointment**\n",
    "- **Type**: Categorical (int, treated as binary)\n",
    "- **Analysis**: Indicates whether other types of follow-ups occurred before scheduling a completed PrEP appointment.\n",
    "\n",
    "#### **Text Follow up Between Scheduling and Completed PrEP Appointment Date**\n",
    "- **Type**: Categorical (int, treated as binary)\n",
    "- **Analysis**: Indicates whether a text follow-up occurred between scheduling and the completed PrEP appointment date.\n",
    "\n",
    "#### **Call Follow up Between Scheduling and Completed PrEP Appointment Date**\n",
    "- **Type**: Categorical (int, treated as binary)\n",
    "- **Analysis**: Indicates whether a call follow-up occurred between scheduling and the completed PrEP appointment date.\n",
    "\n",
    "#### **Email Follow up Between Scheduling and Completed PrEP Appointment Date**\n",
    "- **Type**: Categorical (int, treated as binary)\n",
    "- **Analysis**: Indicates whether an email follow-up occurred between scheduling and the completed PrEP appointment date.\n",
    "\n",
    "#### **Other Follow up Between Scheduling and Completed PrEP Appointment Date**\n",
    "- **Type**: Categorical (int, treated as binary)\n",
    "- **Analysis**: Indicates whether other types of follow-ups occurred between scheduling and the completed PrEP appointment date.\n",
    "\n",
    "#### **First Completed PrEP Appointment Scheduled Date**\n",
    "- **Type**: Date (or potentially categorical if encoded differently)\n",
    "- **Analysis**: The date when the first PrEP appointment was scheduled.\n",
    "\n",
    "#### **First Completed PrEP Appointment Date**\n",
    "- **Type**: Date (or potentially categorical if encoded differently)\n",
    "- **Analysis**: The date when the first PrEP appointment was completed.\n",
    "\n",
    "#### **Telehealth type**\n",
    "- **Type**: Categorical (str)\n",
    "- **Analysis**: Indicates whether the appointment was telehealth or in-person.\n",
    "\n",
    "#### **Number of Previous Incomplete appointments**\n",
    "- **Type**: Numerical (int)\n",
    "- **Analysis**: Number of previous incomplete appointments.\n",
    "\n",
    "#### **Previous Incomplete appointments type**\n",
    "- **Type**: Categorical (str)\n",
    "- **Analysis**: The type of previous incomplete appointments.\n",
    "\n",
    "#### **Provider**\n",
    "- **Type**: Categorical (str)\n",
    "- **Analysis**: The healthcare provider for the appointment.\n",
    "\n",
    "#### **Timeslot**\n",
    "- **Type**: Categorical (str)\n",
    "- **Analysis**: The time of day when the appointment occurred.\n",
    "\n",
    "#### **Day of week**\n",
    "- **Type**: Categorical (str)\n",
    "- **Analysis**: The day of the week when the appointment occurred.\n",
    "\n",
    "#### **Month**\n",
    "- **Type**: Categorical (str)\n",
    "- **Analysis**: The month when the appointment occurred.\n",
    "\n",
    "#### **Waiting time(Days)**\n",
    "- **Type**: Numerical (int)\n",
    "- **Analysis**: The number of days the patient waited for the appointment.\n",
    "\n",
    "#### **Time spent at clinic(Min)**\n",
    "- **Type**: Numerical (int)\n",
    "- **Analysis**: The number of minutes the patient spent at the clinic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5628c166",
   "metadata": {},
   "source": [
    "### Remove the Influencer column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2e18ab3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minsurance\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m column\u001b[38;5;241m.\u001b[39mlower():\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDropping column: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    if 'insurance' in column.lower():\n",
    "        print(f\"Dropping column: {column}\")\n",
    "        df.drop(column, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dda77e2",
   "metadata": {},
   "source": [
    "### Creating binary indicator for latefill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deb81b2",
   "metadata": {},
   "source": [
    "The binary indicator for 'latefill' is created to classify whether a \"Fill shipment waiting period\" exceeds a certain threshold, in this case, 30 days. This threshold is used to determine if the shipment was \"late\" or \"on time.\" This binary classification can be useful in identifying patterns or relationships that are associated with late shipments.. The analysis is also simplified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac80a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the binary indicator for latefill\n",
    "df['latefill'] = df['Fill shipment waiting period'].apply(lambda x: 1 if x > 30 else (0 if x <= 30 else np.nan))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319b761c",
   "metadata": {},
   "source": [
    "### Creating the clinic column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc22811",
   "metadata": {},
   "source": [
    "We replace occurrences of the clinic name 'Woodland' with 'Louisville'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd0bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clinic'] = df['Clinic assigned to'].replace('Woodland', 'Louisville')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b32a65",
   "metadata": {},
   "source": [
    "### Filling in missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc72ff7",
   "metadata": {},
   "source": [
    "We fill in missing values for 'Zip Code' and 'City' using the mode (most common value). This is done to ensure data completeness and avoid issues during analysis or model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd34be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and fill missing values in 'Zip Code'\n",
    "if int(df['Zip Code'].isna().sum()) > 0:\n",
    "    print(f\"Nulls found in Zip Code column: {int(df['Zip Code'].isna().sum())}\")\n",
    "    print(f\"Filling missing values with mode...\")\n",
    "    df['Zip Code'] = df['Zip Code'].fillna(df['Zip Code'].mode()[0])\n",
    "    print(f\"Nulls in Zip Code column after imputing: {int(df['Zip Code'].isna().sum())}\")\n",
    "else:\n",
    "    print(f\"No nulls found in Zip Code column.\")\n",
    "\n",
    "# Check and fill missing values in 'City'\n",
    "if int(df['City'].isna().sum()) > 0:\n",
    "    print(f\"\\nNulls found in City column: {int(df['City'].isna().sum())}\")\n",
    "    print(f\"Filling missing values with mode...\")\n",
    "    df['City'] = df['City'].fillna(df['City'].mode()[0])\n",
    "    print(f\"Nulls in City column after imputing: {int(df['City'].isna().sum())}\")\n",
    "else:\n",
    "    print(f\"\\nNo nulls found in City column.\")\n",
    "\n",
    "# If there are nulls in Provider column then set them to \"Unknown\"\n",
    "if int(df['Provider'].isna().sum()) > 0:\n",
    "    print(f\"\\nNulls founds in Provider column: {int(df['Provider'].isna().sum())}\")\n",
    "    print(f\"Filling nulls with 'Unknown\")\n",
    "    df['Provider'] = df['Provider'].fillna('Unknown')\n",
    "    print(f\"Nulls in Provider column after imputing: {int(df['Provider'].isna().sum())}\")\n",
    "else:\n",
    "    print(f\"\\nNo nulls found in Provider column.\")\n",
    "    \n",
    "# Check and fill missing values in 'Time spent at clinic(Min)'\n",
    "if int(df['Time spent at clinic(Min)'].isna().sum()) > 0:\n",
    "    print(f\"\\nNulls found in 'Time spent at clinic(Min)' column: {int(df['Time spent at clinic(Min)'].isna().sum())}\")\n",
    "    print(f\"Filling missing values with median...\")\n",
    "    df['Time spent at clinic(Min)'] = df['Time spent at clinic(Min)'].fillna(df['Time spent at clinic(Min)'].median())\n",
    "    print(f\"Nulls in 'Time spent at clinic(Min)' column after imputing: {int(df['Time spent at clinic(Min)'].isna().sum())}\")\n",
    "else:\n",
    "    print(f\"\\nNo nulls found in 'Time spent at clinic(Min)' column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd249aa",
   "metadata": {},
   "source": [
    "Categorize the 'Time spent at clinic(Min)' column into defined time intervals (bins). We group the continuous values into categories such as '< 30', '30 to 60', '60 to 90', '90 to 120', and '> 120'. The pd.cut function creates a new column 'Minutes_Spent_at_Clinic' representing these intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cf4a01d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Q1 \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime spent at clinic(Min)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.25\u001b[39m)  \u001b[38;5;66;03m# First quartile (25th percentile)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m Q3 \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime spent at clinic(Min)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.75\u001b[39m)  \u001b[38;5;66;03m# Third quartile (75th percentile)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m IQR \u001b[38;5;241m=\u001b[39m Q3 \u001b[38;5;241m-\u001b[39m Q1  \u001b[38;5;66;03m# Interquartile range\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "Q1 = df['Time spent at clinic(Min)'].quantile(0.25)  # First quartile (25th percentile)\n",
    "Q3 = df['Time spent at clinic(Min)'].quantile(0.75)  # Third quartile (75th percentile)\n",
    "IQR = Q3 - Q1  # Interquartile range\n",
    "\n",
    "# Define outlier boundaries\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out rows where 'Time spent at clinic(Min)' is an outlier\n",
    "df_filtered = df[(df['Time spent at clinic(Min)'] >= lower_bound) & (df['Time spent at clinic(Min)'] <= upper_bound)]\n",
    "\n",
    "\n",
    "df['Minutes_Spent_at_Clinic'] = pd.cut(\n",
    "    df['Time spent at clinic(Min)'],\n",
    "    bins=[-float('inf'), 30, 60, 90, 120, float('inf')],\n",
    "    labels=['< 30', '30 to 60', '60 to 90', '90 to 120', '> 120'],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "df['Minutes_Spent_at_Clinic'].value_counts(dropna=False, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0f4fe2",
   "metadata": {},
   "source": [
    "### Create the target column Shipment Occurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664226c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"First Shipped Date After Completed Appointment\"\n",
    "df['Shipment_Occurred'] = df[target_column].apply(lambda x: 0 if pd.isnull(x) else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5e4c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime format\n",
    "df['First Completed PrEP Appointment Scheduled Date'] = pd.to_datetime(df['First Completed PrEP Appointment Scheduled Date'])\n",
    "df['First Completed PrEP Appointment Date'] = pd.to_datetime(df['First Completed PrEP Appointment Date'])\n",
    "\n",
    "# Display the data types to confirm conversion\n",
    "df[['First Completed PrEP Appointment Scheduled Date', 'First Completed PrEP Appointment Date']].dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e006bf9a",
   "metadata": {},
   "source": [
    "### Extract Date Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571e8aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date components (month, day of the week) from the date columns\n",
    "df['Scheduled_Month'] = df['First Completed PrEP Appointment Scheduled Date'].dt.month\n",
    "df['Scheduled_DayOfWeek'] = df['First Completed PrEP Appointment Scheduled Date'].dt.dayofweek\n",
    "df['Appointment_Month'] = df['First Completed PrEP Appointment Date'].dt.month\n",
    "df['Appointment_DayOfWeek'] = df['First Completed PrEP Appointment Date'].dt.dayofweek\n",
    "\n",
    "# Display the first few rows to verify the new columns\n",
    "df[['Scheduled_Month', 'Scheduled_DayOfWeek', 'Appointment_Month', 'Appointment_DayOfWeek']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1712f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = (\n",
    "    df.dropna(subset=['Provider'])\n",
    "      .loc[lambda x: x['Provider'].map(x['Provider'].value_counts()) >= 250]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925baee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.groupby('Provider').agg(\n",
    "    total=pd.NamedAgg(column='Shipment_Occurred', aggfunc='count'),\n",
    "    shipped=pd.NamedAgg(column='Shipment_Occurred', aggfunc='sum'),\n",
    "    percentage_shipped=pd.NamedAgg(column='Shipment_Occurred', aggfunc='mean')\n",
    ").reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4545b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_counts = df['City'].value_counts()\n",
    "provider_counts = df['Provider'].value_counts()\n",
    "zip_counts = df['Zip Code'].value_counts()\n",
    "\n",
    "df['city_ft'] = df['City'].apply(lambda x: 'rare_city' if pd.notna(x) and city_counts.loc[x] < 50 else x)\n",
    "df['provider_ft'] = df['Provider'].apply(lambda x: 'rare_provider' if pd.notna(x) and provider_counts.loc[x] < 50 else x)\n",
    "df['zipcode_ft'] = df['Zip Code'].apply(lambda x: 'rare_zipcode' if pd.notna(x) and zip_counts.loc[x] < 50 else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec34b9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "'Ethnicity', \n",
    "'Race', \n",
    "'clinic', \n",
    "'Telehealth type', \n",
    "'city_ft',\n",
    "'provider_ft']\n",
    "\n",
    "df_encoded = pd.get_dummies(df[categorical_columns], drop_first=True)\n",
    "other_columns = [\n",
    "'Age',\n",
    "'Waiting time(Days)',\n",
    "'Time spent at clinic(Min)',\n",
    "'Text Follow up Prior Scheduling Completed PrEP Appointment',               \n",
    "'Call Follow up Prior Scheduling Completed PrEP Appointment', \n",
    "'Email Follow up Prior Scheduling Completed PrEP Appointment',                  \n",
    "'Other Follow up Prior Scheduling Completed PrEP Appointment',                 \n",
    "'Text Follow up Between Scheduling and Completed PrEP Appointment Date',      \n",
    "'Call Follow up Between Scheduling and Completed PrEP Appointment Date',       \n",
    "'Email Follow up Between Scheduling and Completed PrEP Appointment Date' ,     \n",
    "'Other Follow up Between Scheduling and Completed PrEP Appointment Date',\n",
    "'Number of Previous Incomplete appointments']\n",
    "\n",
    "\n",
    "df_other = df[other_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31df30a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.to_csv('data/Dataset after cleaning & encoding.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8e5b49",
   "metadata": {},
   "source": [
    "### Class Balancing using SMOTE + Tomek Links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df0716",
   "metadata": {},
   "source": [
    "SMOTE (Synthetic Minority Over-sampling Technique): SMOTE addresses class imbalance by generating synthetic examples for the minority class. Instead of simply duplicating minority class samples, SMOTE creates new synthetic data points by interpolating between existing minority class samples. This helps increase the number of minority class samples in a way that introduces variability, making the dataset less biased toward the majority class.\n",
    "\n",
    "Tomek Links: After using SMOTE to balance the classes, Tomek Links are applied to further clean the dataset. A Tomek Link occurs when two samples (one from the majority class and one from the minority class) are very close to each other in feature space, meaning they are potential sources of misclassification. Tomek Links remove these samples (usually from the majority class) to create a clearer boundary between the classes, improving the model's ability to differentiate between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10984407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the label column name\n",
    "label_column = 'Shipment_Occurred'\n",
    "\n",
    "# Combine relevant features from df_other (numerical), df_encoded (categorical), and the target label column\n",
    "feature_set = pd.concat([df_other, df_encoded, df[[label_column]]], axis=1)\n",
    "\n",
    "# Separate the feature matrix (X) and the target variable (y)\n",
    "X = feature_set.drop(label_column, axis=1)  # Feature matrix\n",
    "y = feature_set[label_column]               # Target variable\n",
    "\n",
    "# Handle missing values in X:\n",
    "X.fillna(X.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Fill NaN values in categorical columns with the mode (most frequent value) of each column.\n",
    "X.fillna(X.mode().iloc[0], inplace=True)\n",
    "\n",
    "\n",
    "# Show the distribution of the target variable before applying hybrid sampling\n",
    "print(\"Before Hybrid Sampling (Target Distribution):\")\n",
    "print(y.value_counts())  # Shows the count of each class (e.g., 0s and 1s)\n",
    "\n",
    "# Perform hybrid sampling using SMOTE + Tomek Links to balance the classes\n",
    "# SMOTE generates synthetic samples for the minority class, and Tomek Links removes noisy examples.\n",
    "smote_tomek = SMOTETomek(random_state=42)   # Initialize SMOTE + Tomek Links with a fixed random seed for reproducibility\n",
    "X_resampled, y_resampled = smote_tomek.fit_resample(X, y)  # Apply hybrid sampling to balance the dataset\n",
    "\n",
    "# Show the distribution of the target variable after hybrid sampling\n",
    "print(\"\\nAfter Hybrid Sampling (Target Distribution):\")\n",
    "print(y_resampled.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54162fe9",
   "metadata": {},
   "source": [
    "### XGBoost Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b0faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid with ranges for random search\n",
    "param_distributions = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'reg_lambda': [1, 0.1, 0]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost classifier model with eval_metric in the initialization\n",
    "xgb_model = XGBClassifier(eval_metric='logloss')\n",
    "\n",
    "# Use RandomizedSearchCV for hyperparameter tuning\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    scoring='accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Split the resampled dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model using random search for hyperparameter tuning\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "# Print the best hyperparameters and score\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Cross-Validation Accuracy: {best_score:.4f}\")\n",
    "\n",
    "# Prepare the final model with early stopping, include eval_metric in the initialization\n",
    "final_xgb_model = XGBClassifier(**best_params, eval_metric='logloss')\n",
    "\n",
    "# Set up evaluation results to track training progress\n",
    "eval_results = {}\n",
    "\n",
    "\n",
    "# Prepare the final model with early stopping\n",
    "final_xgb_model = XGBClassifier(**best_params, eval_metric=['logloss', 'error'])\n",
    "\n",
    "# Train the final model\n",
    "final_xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Get the evaluation results\n",
    "results = final_xgb_model.evals_result()\n",
    "\n",
    "# Plot the evaluation metrics (logloss and error) over boosting rounds\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot logloss for both training and validation sets\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(results['validation_0']['logloss'], label='Train')\n",
    "plt.plot(results['validation_1']['logloss'], label='Test')\n",
    "plt.xlabel('Boosting Rounds')\n",
    "plt.ylabel('Logloss')\n",
    "plt.title('Logloss Over Boosting Rounds')\n",
    "plt.legend()\n",
    "\n",
    "# Plot error for both training and validation sets\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(results['validation_0']['error'], label='Train')\n",
    "plt.plot(results['validation_1']['error'], label='Test')\n",
    "plt.xlabel('Boosting Rounds')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Error Over Boosting Rounds')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final model performance\n",
    "y_pred = final_xgb_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Final Model Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f302bdc",
   "metadata": {},
   "source": [
    "The plots display the logloss and error over boosting rounds for both the training and test datasets. In the logloss plot, we see a consistent decline for both the training and test datasets as the number of boosting rounds increases, indicating that the model is learning and improving its performance by reducing the error in predictions. However, the test set logloss decreases at a slower pace compared to the training set, which may indicate slight overfitting as the model fits the training data more closely than the test data. In the error plot, both the training and test errors drop significantly in the initial boosting rounds, but the test error stabilizes at a higher value than the training error, again suggesting possible overfitting. The final test error stabilizes, indicating the model is not deteriorating with additional boosting rounds, but the gap between training and test performance should be monitored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad63f2",
   "metadata": {},
   "source": [
    "### Model Evaluation (Accuracy, Precision, Recall, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b514b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = final_xgb_model.predict(X_test)  # Predicted class labels\n",
    "y_pred_proba = final_xgb_model.predict_proba(X_test)[:, 1]  # Predicted probabilities for the positive class (1)\n",
    "\n",
    "# Evaluate the model's performance using various metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4957561a",
   "metadata": {},
   "source": [
    "### Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533081a3",
   "metadata": {},
   "source": [
    "By looking at feature importance, we can understand which features are driving the predictions. This helps interpret the model's decisions and gives insight into which variables are the most impactful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04df11bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importance using XGBoost's built-in method\n",
    "xgb_importances = final_xgb_model.feature_importances_\n",
    "\n",
    "# Sort and plot feature importance\n",
    "sorted_idx = np.argsort(xgb_importances)\n",
    "plt.figure(figsize=(12, 15))  # Increase figure size for better readability\n",
    "plt.barh(range(len(sorted_idx)), xgb_importances[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), X_train.columns[sorted_idx])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importance from XGBoost Model')\n",
    "\n",
    "# Apply tight layout to avoid overlap of labels\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b73f2e1",
   "metadata": {},
   "source": [
    "The features at the top which are \"Race_Black,\" \"Race_White,\" and \"clinic_MCPC East,\" are the features which have the most influence on the model's predictions. These features are used more frequently or effectively in the trees to make accurate predictions.\n",
    "Features near the bottom, such as \"Ethnicity_Dominican,\" \"Email Follow up Between Scheduling and Completed PrEP Appointment Date,\" and \"Race_Middle Eastern or North African,\" have very little influence on the model's performance. The model uses them less frequently or they don’t provide much predictive power.\n",
    "The graph is sorted in descending order of feature importance, which makes it easy to see which features contribute the most to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfd591d",
   "metadata": {},
   "source": [
    "### SHAP Analysis for Model Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b94521",
   "metadata": {},
   "source": [
    "The SHAP summary plot provides a global view of feature importance and how feature values impact model predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac38229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SHAP explainer with the trained XGBoost model\n",
    "explainer = shap.TreeExplainer(final_xgb_model)\n",
    "\n",
    "# Calculate SHAP values for the test dataset\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Plot summary plot for SHAP values (global feature importance)\n",
    "shap.summary_plot(shap_values, X_test, feature_names=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25be162a",
   "metadata": {},
   "source": [
    "\"Race_Black\" and \"city_ft_NASHVILLE\" have a strong positive influence on the model’s predictions for higher outcomes.\n",
    "\"Waiting time(Days)\" shows that longer waiting times tend to increase the predicted outcome, while shorter waiting times have a mixed impact.\n",
    "Some features, like \"provider_ft_William, Manley\" and \"provider_ft_Anne, Sizemore,\" have relatively lower and more uniform impacts on the predictions, meaning they contribute less to the overall predictions of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f9fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_top_features = shap_values[:, :4]\n",
    "\n",
    "# Generate the force plot for the top N features\n",
    "shap.force_plot(explainer.expected_value, shap_values[0, :4], X_test.iloc[0, :4], matplotlib=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d78d18",
   "metadata": {},
   "source": [
    "The SHAP force plot explains how the top 4 selected features contribute to an individual prediction. The base value represents the average model output, and the prediction moves either higher or lower based on the contributions of the features. In this plot, \"Text Follow up Prior Scheduling Completed PrEP Appointment = 0.0\" and \"Waiting time(Days) = 1.0\" are pushing the prediction higher (colored red), meaning they increase the predicted outcome, while \"Age = 32.0\" and \"Time spent at clinic(Min) = 58.0\" push the prediction slightly lower (colored blue), decreasing the predicted outcome. The final predicted value, represented as f(x), is 0.15. We have selected 4 features to avoid overlapping names in teh plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e94e6dc",
   "metadata": {},
   "source": [
    "### Partial Dependence Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311ba88f",
   "metadata": {},
   "source": [
    "Partial dependence plots are useful because they help visualize the relationship between specific features and the predicted outcome, while holding all other features constant. This allows you to see how changes in a single feature impact the model's predictions, providing insights into the model's behavior and feature importance. They are particularly valuable for understanding non-linear relationships, detecting feature interactions, and offering interpretability in complex models by showing how a feature influences predictions across its range of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257dbb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot partial dependence for features\n",
    "features_to_plot = [0, 1, 2]  # Features to plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "PartialDependenceDisplay.from_estimator(final_xgb_model, X_train, features_to_plot, ax=ax)\n",
    "plt.suptitle('Partial Dependence Plot')\n",
    "plt.subplots_adjust(top=0.9) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ca0a3f",
   "metadata": {},
   "source": [
    "In the plot, three features are displayed: \"Age,\" \"Waiting time(Days),\" and \"Time spent at clinic(Min).\" The y-axis represents the predicted probability (partial dependence) of the target, while the x-axis shows the values of the corresponding feature. For \"Age,\" the plot shows that as age increases, the probability gradually increases, with some fluctuations around the mid-40s to 60s. \"Waiting time(Days)\" shows a steep increase in probability with longer waiting times, stabilizing after a few days. \"Time spent at clinic(Min)\" has a generally upward trend, indicating that spending more time at the clinic slightly increases the predicted probability, though there are small variations. These plots help visualize the relationship between each feature and the model's prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7114ac5b",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36dd752",
   "metadata": {},
   "source": [
    "The Receiver Operating Characteristic (ROC) curve plots the True Positive Rate (Sensitivity) against the False Positive Rate (1 - Specificity) at various threshold settings. The curve helps evaluate the performance of a binary classifier. A model with a curve closer to the top left corner is better, indicating higher true positives with fewer false positives. The diagonal line represents random guessing, and the further the ROC curve is above this line, the better the model's performance. The area under the curve (AUC) provides a single metric summarizing the model's ability to distinguish between classes, with a value closer to 1 indicating better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242210f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Receiver Operating Characteristic (ROC) curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')  # ROC curve\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Diagonal line representing random guessing\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aa96b8",
   "metadata": {},
   "source": [
    "An AUC of 0.93 shows that the model performs well in distinguishing between the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492d1d50",
   "metadata": {},
   "source": [
    "### LightGBM Model training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f76924",
   "metadata": {},
   "source": [
    "LightGBM is a gradient boosting framework that builds decision trees in a sequential manner, where each tree is designed to correct the errors of the previous trees. It follows the principles of gradient boosting, but with optimizations that make it faster and more efficient than other gradient-boosting algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351677b1",
   "metadata": {},
   "source": [
    "LightGBM uses a leaf-wise growth strategy, as opposed to XGBoost’s level-wise growth. This approach grows the tree by splitting the leaf with the highest loss, which often results in smaller, more efficient trees that can achieve higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277c8c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to clean feature names by removing special characters\n",
    "def clean_feature_names(df):\n",
    "    df.columns = [re.sub(r'\\W+', '_', col) for col in df.columns]  # Replace non-alphanumeric characters with an underscore\n",
    "    return df\n",
    "\n",
    "# Apply the function to your feature matrix (X_train and X_test)\n",
    "X_train = clean_feature_names(X_train)\n",
    "X_test = clean_feature_names(X_test)\n",
    "\n",
    "# Train the LightGBM model again\n",
    "from lightgbm import LGBMClassifier\n",
    "model = LGBMClassifier()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e436394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate AUC-ROC\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f'AUC-ROC: {auc_score:.4f}')\n",
    "\n",
    "# Print detailed classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed44353",
   "metadata": {},
   "source": [
    "LightGBM model is performing quite well, with an accuracy of 87.5% and an AUC-ROC of 93.15%. The precision, recall, and F1-scores are well-balanced, particularly for class 1 (shipment occurred), where the model shows high recall (93%), meaning it’s very good at identifying the positive class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
